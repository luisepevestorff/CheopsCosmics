{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy.stats import binned_statistic_2d\n",
    "from functions import *\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = Path.cwd()/\"output_plots\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and read the dataframe from cn04 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "filename = cwd / \"/Users/alexisheitzmann/Documents/CHEOPS/Code/SAA_monitoring_MC/CheopsCosmics/data_2023_06_24_to_2023_07_02.pkl\"\n",
    "data_file = Path(filename)\n",
    "\n",
    "all_data = pd.read_pickle(data_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_function(data_to_plot, title):\n",
    "    \n",
    "    def plotimg(idx):\n",
    "        # Update histogram\n",
    "        ax[0].clear()\n",
    "        ax[0].hist(data_to_plot[int(idx)].flatten(), bins = len(np.unique(data_to_plot[int(idx)].flatten())))\n",
    "        # Update image\n",
    "        img.set_data(data_to_plot[int(idx),:,:])\n",
    "        im = ax[1].imshow(data_to_plot[int(idx),:,:], origin='lower', cmap = 'viridis')\n",
    "        ax[0].axvline(np.nanmedian(data_to_plot[int(idx),:,:]), c = 'r',  alpha = 0.5) # median pixel value\n",
    "        ax[0].axvline(np.nanmean(data_to_plot[int(idx),:,:]), c = 'g', alpha = 0.5) # mean pixel value\n",
    "        #plt.colorbar(im)\n",
    "        fig.canvas.draw_idle()\n",
    "        \n",
    "    fig, ax = plt.subplots(ncols = 2, figsize=(12,4))\n",
    "    img = ax[1].imshow(data_to_plot[0], origin='lower')\n",
    "    #colorbar = plt.colorbar(img)\n",
    "    ax[0].set_xlabel('Brightness')\n",
    "    ax[0].set_ylabel('Nb of pixels')\n",
    "    plt.suptitle(title, weight = 'bold')\n",
    "\n",
    "    ipywidgets.interact(plotimg, idx = ipywidgets.FloatSlider(value=0,min=0,max=np.shape(data_to_plot)[0]-1,step=1))\n",
    "    plt.show()\n",
    "    \n",
    "def apply_filters(data, filter_names, values, reverse_filters):\n",
    "    \n",
    "    # Available filters ['latitude-','latitude+','visit','density_cosmics','nb_cosmics','no_straylight','largest_cosmics','percentage_cosmics']\n",
    "    list_filter_names = ['time-','time+','latitude-','latitude+','visit','density_cosmics','nb_cosmics','no_straylight','largest_cosmics','percentage_cosmics']\n",
    "    \n",
    "    filtered_data = data.copy()\n",
    "    \n",
    "    for filter_name, value, reverse in zip(filter_names,values, reverse_filters): \n",
    "        \n",
    "        if reverse:\n",
    "            inf = '>'\n",
    "            sup = '<'\n",
    "        else: \n",
    "            inf = '<'\n",
    "            sup = '>'\n",
    "            \n",
    "        if filter_name == 'time-':\n",
    "            print(f\"Keep data {sup} {value}\")\n",
    "            filter_to_apply = filtered_data['time'] >= value\n",
    "        elif filter_name == 'time+':\n",
    "            print(f\"Keep data {inf} {value}\")\n",
    "            filter_to_apply = filtered_data['time'] <= value\n",
    "        elif filter_name == 'latitude-':\n",
    "            print(f\"Kepp data with latitude {sup} {value}\")\n",
    "            filter_to_apply = filtered_data['LATITUDE'] > value\n",
    "        elif filter_name == 'latitude+':\n",
    "            print(f\"Keep with latitude {inf} {value}\")\n",
    "            filter_to_apply = filtered_data['LATITUDE'] < value  \n",
    "        elif filter_name == 'visit':\n",
    "            print(f\"Keep data only from {value}\")\n",
    "            filter_to_apply = filtered_data['visit_ID'] == value\n",
    "        elif filter_name == 'density_cosmics':\n",
    "            print(f\"Keep data only with a density of cosmics {sup} {value}\")\n",
    "            filter_to_apply = filtered_data['density_cosmics'] > value        \n",
    "        elif filter_name == 'nb_cosmics':\n",
    "            print(f\"Keep data only with a number of cosmics {sup} {value}\")\n",
    "            filter_to_apply = filtered_data['nb_cosmics'] > value        \n",
    "        elif filter_name == 'no_straylight':\n",
    "            if reverse:\n",
    "                print(f\"Keep data only affected with straylight\")\n",
    "            else:\n",
    "                print(f\"Keep data only not affected with straylight\")\n",
    "            filter_to_apply = filtered_data['straylight_boolean']\n",
    "            filter_to_apply = ~filter_to_apply\n",
    "        elif filter_name == 'largest_cosmics':\n",
    "            print(f\"Keep data only with a largest cosmic {inf} {value}\")\n",
    "            filter_to_apply = filtered_data['largest_cosmics'] < value\n",
    "        elif filter_name == 'percentage_cosmics':\n",
    "            print(f\"Keep data images with {inf} {value}% of pixels affected by cosmics\")\n",
    "            filter_to_apply = filtered_data['percentage_cosmics'] < value\n",
    "        else:\n",
    "            print(f\"{filter_name} not in {list_filter_names}\")   \n",
    "            \n",
    "        # apply filter \n",
    "        if reverse:\n",
    "            filter_to_apply = ~filter_to_apply\n",
    "\n",
    "        nb_points = len(filtered_data)\n",
    "        filtered_data = filtered_data[filter_to_apply]\n",
    "        nb_datapoints_remomoved =  nb_points - len(filtered_data)\n",
    "        print(f\"Removed {nb_datapoints_remomoved} data points, kept {len(filtered_data)}\")\n",
    "        \n",
    "    return filtered_data\n",
    "\n",
    "def bin_data(x,y,c,interpolation = 'None', type = None):\n",
    "    \n",
    "    # Bin and maks SAA mask contour\n",
    "    lon_min, lon_max = -180, 180\n",
    "    lat_min, lat_max = -90, 90\n",
    "\n",
    "    # interpolation can be 'None, 'base_grid' or 'fine_grid'\n",
    "    \n",
    "    from scipy.interpolate import RBFInterpolator\n",
    "    bin_size = 5\n",
    "    x_bins = np.arange(lon_min+bin_size, lon_max, bin_size)\n",
    "    y_bins = np.arange(lat_min+bin_size, lat_max, bin_size)\n",
    "    \n",
    "    # bin\n",
    "    ret = binned_statistic_2d(x, y, c, statistic='median', bins=[x_bins, y_bins])\n",
    "\n",
    "    # Get the array of bin values and the bin edges\n",
    "    statistic = ret.statistic.T\n",
    "    x_edges = ret.x_edge\n",
    "    y_edges = ret.y_edge\n",
    "\n",
    "    # Compute the bin centers\n",
    "    bin_centers_x = (x_edges[:-1] + x_edges[1:]) / 2\n",
    "    bin_centers_y = (y_edges[:-1] + y_edges[1:]) / 2\n",
    "    X, Y = np.meshgrid(bin_centers_x, bin_centers_y)\n",
    "\n",
    "    # Flatten the arrays for easier indexing\n",
    "    points = np.column_stack([X.ravel(), Y.ravel()])\n",
    "    values = statistic.ravel()\n",
    "\n",
    "    # Remove NaN values from the points and values\n",
    "    mask = ~np.isnan(values)\n",
    "    valid_points = points[mask]\n",
    "    valid_values = values[mask]\n",
    "\n",
    "    # Define a finer grid for finer interpolation\n",
    "    nb_points_finer_grid = 200\n",
    "    finer_x = np.linspace(bin_centers_x.min(), bin_centers_x.max(), nb_points_finer_grid)  # More points\n",
    "    finer_y = np.linspace(bin_centers_y.min(), bin_centers_y.max(), nb_points_finer_grid)  # More points\n",
    "    Finer_X, Finer_Y = np.meshgrid(finer_x, finer_y)\n",
    "\n",
    "    # Flatten the finer grid for interpolation\n",
    "    finer_points = np.column_stack([Finer_X.ravel(), Finer_Y.ravel()])\n",
    "\n",
    "    # Use the same valid_points and valid_values from the previous example\n",
    "    interpolator = RBFInterpolator(valid_points, valid_values, kernel='linear', smoothing = 0)\n",
    "    \n",
    "    # Interpolate\n",
    "    if interpolation == 'None':\n",
    "        print(\"No interpolation\")\n",
    "        statistic = ret.statistic.T\n",
    "        lon_mesh = None\n",
    "        lat_mesh = None\n",
    "    elif interpolation == 'base_grid':\n",
    "        print(f\"Interpolating on the {bin_size} degrees grid\")\n",
    "        values = interpolator(points)\n",
    "        statistic = values.reshape(X.shape)\n",
    "        lon_mesh = X\n",
    "        lat_mesh = Y\n",
    "    elif interpolation == 'fine_grid':\n",
    "        print(f\"Interpolating on a finer grid\")\n",
    "        finer_values = interpolator(finer_points)\n",
    "        statistic = finer_values.reshape(Finer_X.shape)\n",
    "        lon_mesh = Finer_X\n",
    "        lat_mesh = Finer_Y\n",
    "    if type == 'density_cosmics':\n",
    "        # set low values to 1\n",
    "        mask_low_values = statistic < 1\n",
    "        statistic[mask_low_values] = 1\n",
    "    elif type == 'percentage_cosmics':\n",
    "        # set low values to 0.01\n",
    "        mask_low_values = statistic < 0.01\n",
    "        statistic[mask_low_values] = 0.01\n",
    "    else:\n",
    "        print(\"Please set type to convert low values, convertion ignored\")\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    return statistic, bin_centers_x, bin_centers_y, lon_mesh, lat_mesh\n",
    "\n",
    "def circle_points(lat, lon, radius, num_points=100):\n",
    "    \"\"\"\n",
    "    Calculate the latitude and longitude points that form a circle of given radius\n",
    "    centered on a given latitude and longitude.\n",
    "\n",
    "    :param lat: Latitude of the center in degrees\n",
    "    :param lon: Longitude of the center in degrees\n",
    "    :param radius: Radius of the circle in degrees (approx. for small circles)\n",
    "    :param num_points: Number of points to generate along the circle\n",
    "    :return: Two numpy arrays (lats, lons) representing the circle's latitude and longitude points\n",
    "    \"\"\"\n",
    "    # Convert radius from degrees to radians\n",
    "    radius_rad = np.deg2rad(radius)\n",
    "\n",
    "    # Generate equally spaced angles around the circle\n",
    "    angles = np.linspace(0, 2 * np.pi, num_points)\n",
    "\n",
    "    # Calculate the latitude and longitude points\n",
    "    latitudes = np.arcsin(np.sin(np.deg2rad(lat)) * np.cos(radius_rad) +\n",
    "                          np.cos(np.deg2rad(lat)) * np.sin(radius_rad) * np.cos(angles))\n",
    "    \n",
    "    longitudes = np.deg2rad(lon) + np.arctan2(np.sin(angles) * np.sin(radius_rad) * np.cos(np.deg2rad(lat)),\n",
    "                                               np.cos(radius_rad) - np.sin(np.deg2rad(lat)) * np.sin(latitudes))\n",
    "    \n",
    "    # Convert the latitude and longitude from radians to degrees\n",
    "    latitudes = np.rad2deg(latitudes)\n",
    "    longitudes = np.rad2deg(longitudes)\n",
    "    \n",
    "    sort_lon = np.argsort(longitudes)\n",
    "\n",
    "    return latitudes[sort_lon], longitudes[sort_lon]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(np.unique(all_data['im_height'])) > 1:\n",
    "    diff_image_types = True # We have different image sizes in all_data\n",
    "    print(f\"Sizes available are {np.unique(all_data['im_height'])}\")\n",
    "else:\n",
    "    diff_image_types = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETECTIONS \n",
    "detections = all_data[all_data['nb_cosmics'] != 0]\n",
    "#detections = all_data[(all_data['density_cosmics'] < 60) & (all_data['density_cosmics'] > 40)]\n",
    "non_detections = all_data[all_data['nb_cosmics'] == 0]\n",
    "\n",
    "max_cosmics = np.max(detections['nb_cosmics'])\n",
    "max_density = np.max(detections['density_cosmics'])\n",
    "\n",
    "print(f'Frame with most cosmics has {max_cosmics} cosmics. largest density is {int(max_density)} hits/cm2/sec')\n",
    "print(f\"{int(len(detections)/len(all_data)*100)}% of visits ({len(detections)}/{len(all_data)}) have detections. {int(len(non_detections))} non detections\\n\")\n",
    "\n",
    "# separate different images sizes\n",
    "if diff_image_types:\n",
    "    size_to_keep = 100\n",
    "    detections_plot = detections[detections['im_height'] == size_to_keep]\n",
    "    non_detections_plot = non_detections[non_detections['im_height'] == size_to_keep]\n",
    "    print(f\"!! Only images of sizes {size_to_keep}*{size_to_keep} are shown !!\\n\")\n",
    "else:     \n",
    "    detections_plot = detections\n",
    "    non_detections_plot = non_detections\n",
    "    \n",
    "## Add other filters \n",
    "# Available filters ['latitude-','latitude+','visit','density_cosmics','nb_cosmics','no_straylight','largest_cosmics', 'percentage_cosmics']\n",
    "filters = ['no_straylight']#,'percentage_cosmics']#,'largest_cosmics']#,'percentage_cosmics','percentage_cosmics']\n",
    "values = [0.05]#,0.3]#,1000]\n",
    "reverse_filters = [True]#, False]\n",
    "\n",
    "print(\"DETECTIONS:\")\n",
    "detections_plot = apply_filters(detections_plot,filters,values,reverse_filters)\n",
    "print(\"\")\n",
    "print(\"NON DETECTIONS:\")\n",
    "non_detections_plot = apply_filters(non_detections_plot,filters,values,reverse_filters)\n",
    "print(\"\")\n",
    "print(\"ALL DATA:\")\n",
    "all_data_filtered = apply_filters(all_data,filters,values,reverse_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affected_visits = np.array(['10_12_39_1', '10_18_403_3', '10_18_437_2',\n",
    "       '10_18_442_3', '10_18_497_5', '10_18_498_4', '10_18_525_2',\n",
    "       '10_24_163_1', '10_25_81_1', '13_57_37_10', '13_57_37_9',\n",
    "       '14_63_14_3', '14_63_14_4', '14_66_4_2', '14_66_4_3',\n",
    "       '14_71_8_3', '14_76_1_4', '14_76_1_5', '14_79_2_1', '14_80_10_2',\n",
    "       '14_80_12_1', '14_84_23_1', '14_84_23_2'])\n",
    "\n",
    "for visit in affected_visits:\n",
    "    \n",
    "    if len(all_data[all_data.visit_ID == visit]) == 0:\n",
    "        print(f'visit:{visit} not here')\n",
    "        continue\n",
    "\n",
    "    ## Add other filters \n",
    "    # Available filters ['latitude-','latitude+','visit','density_cosmics','nb_cosmics','no_straylight','largest_cosmics', 'percentage_cosmics']\n",
    "    filters = ['visit']#,'largest_cosmics']#,'percentage_cosmics','percentage_cosmics']\n",
    "    values = [visit]#, 150]#,1,100]\n",
    "    reverse_filters = [ False]#,False]\n",
    "    data_visit = apply_filters(all_data,filters,values,reverse_filters)\n",
    "\n",
    "    plt.figure(figsize = (8,3))\n",
    "    time_since_visit_start = data_visit.index-data_visit.index[0]\n",
    "    plt.plot(time_since_visit_start,data_visit.percentage_cosmics, 'k.')\n",
    "    # straylight_points = data_visit[data_visit.straylight_boolean]\n",
    "    # time_since_visit_start_stray = time_since_visit_start[data_visit.straylight_boolean]\n",
    "    # plt.plot(time_since_visit_start_stray,straylight_points.percentage_cosmics, 'r.')\n",
    "    plt.axhline(1, color = 'C0',label= '1%')\n",
    "    plt.axhline(5, color = 'C3',label = '5%')\n",
    "    plt.title(np.unique(data_visit.visit_ID)[0])\n",
    "    plt.ylabel('% of pixels affected by CR')\n",
    "    plt.xlabel('Time since visit start [d]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('CR percentage.png', format = 'png', dpi = 600)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot detections and non-detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = True # If False --> non_detections\n",
    "\n",
    "if detection:\n",
    "    str_title = 'DETECTIONS'\n",
    "    data = detections_plot\n",
    "elif ~detection:\n",
    "    str_title = 'NON DETECTIONS'\n",
    "    data = non_detections_plot\n",
    "else:\n",
    "    str_title = 'ALL DATA'\n",
    "\n",
    "\n",
    "data = all_data_filtered  \n",
    "\n",
    "\n",
    "data_to_plot1 = reshape_flatten_images('masked_images', data) \n",
    "data_to_plot2 = reshape_flatten_images('binary_images', data) \n",
    "data_to_plot3 = reshape_flatten_images('derotated_images', data) \n",
    "# data_to_plot4 = reshape_flatten_images('raw_images', data)\n",
    "visit_id = data['visit_ID'].values\n",
    "stacking_order = data['n_exp'].values\n",
    "image_counter = data['img_counter'].values\n",
    "threshold_cosmics = data['threshold_cosmics'].values\n",
    "cosmics = data['nb_cosmics'].values\n",
    "density_cosmics = data['density_cosmics'].values\n",
    "straylight_boolean = data['straylight_boolean'].values\n",
    "largest_cosmics = data['largest_cosmics'].values\n",
    "percentage_cosmics = data['percentage_cosmics'].values\n",
    "\n",
    "def plotimg(idx):\n",
    "    \n",
    "    # Update histogram\n",
    "    ax[0].clear()\n",
    "    ax[0].hist(data_to_plot1[int(idx)].flatten(), bins = 255)#int(np.max(data_to_plot1[int(idx)].flatten())))\n",
    "    #ax[0].set_xlim(0,100)\n",
    "    ax[0].set_ylim(0,2000)\n",
    "    # Update image\n",
    "    img1.set_data(data_to_plot1[int(idx)])\n",
    "    img2.set_data(data_to_plot2[int(idx)])\n",
    "    img3.set_data(data_to_plot3[int(idx)])\n",
    "    ax[1].imshow(data_to_plot1[int(idx)], origin='lower', cmap = 'viridis')\n",
    "    ax[2].imshow(data_to_plot2[int(idx)], origin='lower', cmap = 'viridis')\n",
    "    ax[3].imshow(data_to_plot3[int(idx)], origin='lower', cmap = 'viridis')\n",
    "    # ax[4].imshow(data_to_plot4[int(idx)], origin='lower', cmap = 'viridis')\n",
    "    ax[0].axvline(threshold_cosmics[int(idx)], c = 'r',  alpha = 0.5) # median pixel value\n",
    "    ax[0].text(0.25,0.9,f'{int(cosmics[int(idx)])} CRs detected: {np.round(density_cosmics[int(idx)],1)} CR/cm2/s', weight = 'bold', transform=ax[0].transAxes)\n",
    "    fig.suptitle(f'DETECTIONS for visit {visit_id[int(idx)]}, image {image_counter[int(idx)]}, \\n stacking order {stacking_order[int(idx)]}, straylight flag = {straylight_boolean[int(idx)]}, largest_cosmic = {largest_cosmics[int(idx)]} pixels, {np.round(percentage_cosmics[int(idx)],1)}% pixel affected by cosmics ', weight = 'bold')\n",
    "    #plt.colorbar(im)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "fig, ax = plt.subplots(ncols = 4, figsize=(10,4))\n",
    "img1 = ax[1].imshow(data_to_plot1[0], origin='lower')\n",
    "ax[1].set_title('Masked images')\n",
    "img2 = ax[2].imshow(data_to_plot2[0], origin='lower')\n",
    "ax[2].set_title('Detected cosmic rays')\n",
    "img3 = ax[3].imshow(data_to_plot3[0], origin='lower')\n",
    "ax[3].set_title('Derotated SubArray')\n",
    "#colorbar = plt.colorbar(img)\n",
    "# img4 = ax[4].imshow(np.exp(data_to_plot4[0]), origin='lower')\n",
    "# ax[4].set_title('Original images')\n",
    "\n",
    "ax[0].set_xlabel('Brightness')\n",
    "ax[0].set_ylabel('Nb of pixels')\n",
    "\n",
    "fig.suptitle(f\"DETECTIONS for visit {visit_id[0]}, image {image_counter[0]}, \\n stacking order {stacking_order[0]}\", weight = 'bold')\n",
    "ipywidgets.interact(plotimg, idx = ipywidgets.FloatSlider(value=0,min=0,max=np.shape(data_to_plot1)[0]-1,step=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_straylight_ind = np.array([])\n",
    "\n",
    "data_affected = all_data[all_data['visit_ID'].isin(affected_visits)]\n",
    "images = reshape_flatten_images('binary_images', data_affected)\n",
    "masks = reshape_flatten_images('mask', data_affected)\n",
    "j = 0\n",
    "for img_idx, data_row in data_affected.iterrows():\n",
    "\n",
    "    image_data = data_row\n",
    "    image = images[j]\n",
    "    size = np.shape(image[0])[0]\n",
    "    radius = np.shape(image[0])[0]/2\n",
    "    edges_circular_mask = create_circular_mask(size, radius)\n",
    "    mask = masks[j]\n",
    "    nb_masked_pixels = np.sum(edges_circular_mask | mask.astype(bool)) # number of pixels that are masked (edged + mask)\n",
    "    nb_unmasked_pixels = np.shape(image[0])[0]**2 - nb_masked_pixels\n",
    "\n",
    "    binary_image = images[j].astype(np.uint8)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_image)\n",
    "\n",
    "    binary_image = images[j]\n",
    "    \n",
    "    cosmics_stats = stats[1:,-1]\n",
    "  \n",
    "    if len(cosmics_stats) == 0:\n",
    "        j += 1\n",
    "        continue\n",
    "    \n",
    "    nb_pix_CR = np.sum(cosmics_stats)\n",
    "    largest_pixel = np.max(cosmics_stats)\n",
    "    percentage_pixels_affected = nb_pix_CR/nb_unmasked_pixels*100\n",
    "\n",
    "    stats_no_1_pix = cosmics_stats[cosmics_stats != 1] # 1 to exclude background\n",
    "    nb_CR = len(stats_no_1_pix)\n",
    "    nb_pix_CR_no_1_pix = np.sum(stats_no_1_pix)\n",
    "    percentage_pixels_affected_no_1_pix = nb_pix_CR_no_1_pix/nb_unmasked_pixels*100\n",
    "\n",
    "    pixel_size = 13e-6 # m\n",
    "    cm2_analysed = nb_unmasked_pixels*((pixel_size*1e2)**2) # cm2\n",
    "    density_cosmics = nb_CR/cm2_analysed/image_data['exp_time'] \n",
    "\n",
    "    print(image_data['visit_ID'],image_data['img_counter'])\n",
    "    print(f\"Previous estimation was {np.round(image_data['density_cosmics'],2)} CR/cm2/sec found, new one is {np.round(density_cosmics,2)}\")\n",
    "    print(f\"Previous estimation was {np.round(image_data['percentage_cosmics'],2)}%, new one is {np.round(percentage_pixels_affected,2)}%, excluding 1 pixel CRs {np.round(percentage_pixels_affected_no_1_pix,2)}%\")\n",
    "    print(f\"Largest pixel was {image_data['largest_cosmics']}, new one is {largest_pixel}\")\n",
    "    \n",
    "    \n",
    "    # filters = ['percentage_cosmics','density_cosmics','largest_cosmics']#,'percentage_cosmics','percentage_cosmics']    \n",
    "    # values = [40,100,1000]\n",
    "    # reverse_filters = [False, False, False]\n",
    "\n",
    "    if (percentage_pixels_affected_no_1_pix < 50) & (density_cosmics < 100) & (largest_pixel > 300):\n",
    "        data_test_straylight_ind = np.append(data_test_straylight_ind,img_idx)\n",
    "    \n",
    "    j += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_affected[data_affected.index.isin(data_test_straylight_ind)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "detection = True # If False --> non_detections\n",
    "\n",
    "if detection:\n",
    "    str_title = 'DETECTIONS'\n",
    "    data = data_affected[data_affected.index.isin(data_test_straylight_ind)]\n",
    "else:\n",
    "    str_title = 'NON DETECTIONS'\n",
    "    data = data_affected[data_affected.index.isin(data_test_straylight_ind)]\n",
    "\n",
    "data_to_plot1 = reshape_flatten_images('masked_images', data) \n",
    "data_to_plot2 = reshape_flatten_images('binary_images', data) \n",
    "data_to_plot3 = reshape_flatten_images('derotated_images', data) \n",
    "data_to_plot4 = reshape_flatten_images('raw_images', data)\n",
    "visit_id = data['visit_ID'].values\n",
    "stacking_order = data['n_exp'].values\n",
    "image_counter = data['img_counter'].values\n",
    "threshold_cosmics = data['threshold_cosmics'].values\n",
    "cosmics = data['nb_cosmics'].values\n",
    "density_cosmics = data['density_cosmics'].values\n",
    "straylight_boolean = data['straylight_boolean'].values\n",
    "largest_cosmics = data['largest_cosmics'].values\n",
    "percentage_cosmics = data['percentage_cosmics'].values\n",
    "\n",
    "def plotimg(idx):\n",
    "    \n",
    "    # Update histogram\n",
    "    ax[0].clear()\n",
    "    ax[0].hist(data_to_plot1[int(idx)].flatten(), bins = 255)#int(np.max(data_to_plot1[int(idx)].flatten())))\n",
    "    #ax[0].set_xlim(0,100)\n",
    "    ax[0].set_ylim(0,2000)\n",
    "    # Update image\n",
    "    img1.set_data(data_to_plot1[int(idx)])\n",
    "    img2.set_data(data_to_plot2[int(idx)])\n",
    "    img3.set_data(data_to_plot3[int(idx)])\n",
    "    ax[1].imshow(data_to_plot1[int(idx)], origin='lower', cmap = 'viridis')\n",
    "    ax[2].imshow(data_to_plot2[int(idx)], origin='lower', cmap = 'viridis')\n",
    "    ax[3].imshow(data_to_plot3[int(idx)], origin='lower', cmap = 'viridis')\n",
    "    ax[4].imshow(data_to_plot4[int(idx)], origin='lower', cmap = 'viridis')\n",
    "    ax[0].axvline(threshold_cosmics[int(idx)], c = 'r',  alpha = 0.5) # median pixel value\n",
    "    ax[0].text(0.25,0.9,f'{int(cosmics[int(idx)])} CRs detected: {np.round(density_cosmics[int(idx)],1)} CR/cm2/s', weight = 'bold', transform=ax[0].transAxes)\n",
    "    fig.suptitle(f'DETECTIONS for visit {visit_id[int(idx)]}, image {image_counter[int(idx)]}, \\n stacking order {stacking_order[int(idx)]}, straylight flag = {straylight_boolean[int(idx)]}, largest_cosmic = {largest_cosmics[int(idx)]} pixels, {np.round(percentage_cosmics[int(idx)],1)}% pixel affected by cosmics ', weight = 'bold')\n",
    "    #plt.colorbar(im)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "fig, ax = plt.subplots(ncols = 5, figsize=(10,4))\n",
    "img1 = ax[1].imshow(data_to_plot1[0], origin='lower')\n",
    "ax[1].set_title('Masked images')\n",
    "img2 = ax[2].imshow(data_to_plot2[0], origin='lower')\n",
    "ax[2].set_title('Detected cosmic rays')\n",
    "img3 = ax[3].imshow(data_to_plot3[0], origin='lower')\n",
    "ax[3].set_title('Derotated SubArray')\n",
    "#colorbar = plt.colorbar(img)\n",
    "img4 = ax[4].imshow(np.exp(data_to_plot4[0]), origin='lower')\n",
    "ax[4].set_title('Original images')\n",
    "\n",
    "ax[0].set_xlabel('Brightness')\n",
    "ax[0].set_ylabel('Nb of pixels')\n",
    "\n",
    "fig.suptitle(f\"DETECTIONS for visit {visit_id[0]}, image {image_counter[0]}, \\n stacking order {stacking_order[0]}\", weight = 'bold')\n",
    "ipywidgets.interact(plotimg, idx = ipywidgets.FloatSlider(value=0,min=0,max=np.shape(data_to_plot1)[0]-1,step=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(labels, vmax = 2)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = data.iloc[18]\n",
    "image = data_to_plot2[18]\n",
    "image_suivante = data_to_plot2[17]\n",
    "plt.figure()\n",
    "plt.imshow(image.astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if type_of_visit == 'SAA':\n",
    "#     resituted_orbit = pd.read_pickle('/Users/alexisheitzmann/Documents/CHEOPS/Code/SAA_monitoring_MC/restituted_orbit.pkl')\n",
    "#     fig, ax = plt.subplots(ncols = 2, figsize=(12,4))\n",
    "#     ax[0].plot(resituted_orbit.index,resituted_orbit['LATITUDE'], '.', label = 'restituted orbit')\n",
    "#     ax[0].plot(detections.index,detections['LATITUDE'], '.', label = 'imagettes')\n",
    "#     ax[0].set_title('LATITUDE')\n",
    "#     ax[1].plot(resituted_orbit.index,resituted_orbit['LONGITUDE'], '.', label = 'restituted orbit')\n",
    "#     ax[1].plot(detections.index,detections['LONGITUDE'], '.', label = 'imagettes')\n",
    "#     ax[1].set_title('LONGITUDE')\n",
    "# else:\n",
    "#     print('science visits, no interpolation of orbit')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep data only not affected with straylight\n",
      "Removed 617 data points, kept 5615\n",
      "\n",
      "Visits go from 20-Apr-2023 to 15-Jul-2023\n",
      "There are 16 in total, including 0 SAA visits\n"
     ]
    }
   ],
   "source": [
    "map_data = all_data.copy()\n",
    "\n",
    "projection = ccrs.PlateCarree(-50)\n",
    "# projection = ccrs.Orthographic(0, -90) # South Pole\n",
    "# projection = ccrs.Orthographic(0, 90) # North Pole\n",
    "# projection = ccrs.Orthographic(-42, -26) # SAA_center\n",
    "color_map = 'hot_r'\n",
    "figsize = (12, 8)\n",
    "\n",
    "south_mag_pole_coord = [107.3,-80.7] # from 2020, geomagnetic south pole \n",
    "north_mag_pole_coord = [-72.7,80.7] # from 2020, geomagnetic south pole \n",
    "# projection = ccrs.Orthographic(south_mag_pole_coord[0],south_mag_pole_coord[1]) # South Pole\n",
    "\n",
    "## APPLY FILTER TO DATA ##\n",
    "# Custom filters\n",
    "\n",
    "# Keep only SAA visits \n",
    "start_AO1 = pd.Timestamp(\"2020-02-01 12:00:00\", tz = 'UTC')\n",
    "start_AO2 = pd.Timestamp(\"2021-03-26 12:00:00\", tz = 'UTC')\n",
    "start_AO3 = pd.Timestamp(\"2022-07-01 12:00:00\", tz = 'UTC')\n",
    "start_AO4 = pd.Timestamp(\"2023-09-25 12:00:00\", tz = 'UTC')\n",
    "start_AO5 = pd.Timestamp(\"2024-10-01 12:00:00\", tz = 'UTC')\n",
    "start_LTAN = pd.Timestamp(\"2023-09-21 12:00:00\", tz = 'UTC') # start of LTAN campaign\n",
    "end_LTAN = pd.Timestamp(\"2023-12-20 12:00:00\", tz = 'UTC') # end of LTAN campaign\n",
    "\n",
    "# map_data = map_data[map_data.visit_ID.str[:2] == '34']\n",
    "start_date = pd.Timestamp(\"2023-04-20 00:00:00\", tz = 'UTC')\n",
    "end_date = pd.Timestamp(\"2023-07-15 00:00:00\", tz = 'UTC')\n",
    "\n",
    "\n",
    "# start_date = pd.Timestamp(\"2023-05-07 00:00:00\", tz = 'UTC') # start of LTAN campaign\n",
    "# end_date = pd.Timestamp(\"2023-05-11 00:00:00\", tz = 'UTC') # end of LTAN campaign\n",
    "\n",
    "# start_date = all_data.time.min()\n",
    "# end_date = all_data.time.max()\n",
    "\n",
    "\n",
    "# filters = ['time-','time+','no_straylight','largest_cosmics']\n",
    "# values = [รง None, 100]\n",
    "# reverse_filters = [False, False, False, False]\n",
    "# map_data = apply_filters(map_data,filters,values,reverse_filters)\n",
    "\n",
    "filters = ['no_straylight']#,'latitude-','latitude+']#,'no_straylight','largest_cosmics','percentage_cosmics']\n",
    "values = [0]#,300]#,-45,-10]#,None, 150, 17]\n",
    "reverse_filters = [False, False, False]#,False, False]#, False]\n",
    "map_data = apply_filters(map_data,filters,values,reverse_filters)\n",
    "\n",
    "nb_visits = len(np.unique(map_data.visit_ID))\n",
    "nb_SAA_visits = len(np.unique(map_data[map_data.visit_ID.str[:6] == '34_102'].visit_ID))\n",
    "\n",
    "print(f\"\\nVisits go from {start_date.strftime('%d-%b-%Y')} to {end_date.strftime('%d-%b-%Y')}\")\n",
    "print(f\"There are {nb_visits} in total, including {nb_SAA_visits} SAA visits\")\n",
    "\n",
    "data_plot = map_data\n",
    "\n",
    "x_values = 'LONGITUDE'\n",
    "y_values ='LATITUDE'\n",
    "# hue_values = 'density_cosmics'\n",
    "hue_values = 'percentage_cosmics'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SAA mask\n",
    "\n",
    "SAA_file = Path(\"ref_files\") / \"CH_TU2024-01-16T15-06-00_EXT_APP_SAAMap-690km_V0301.fits\" # post-LTAN\n",
    "\n",
    "data_SAA = read_SAA_map(SAA_file)\n",
    "\n",
    "# Plot SAA mask\n",
    "x = data_SAA['longitude']\n",
    "y = data_SAA['latitude']\n",
    "c = data_SAA['SAA_FLAG']\n",
    "\n",
    "# Bin and maks SAA mask contour\n",
    "lon_min, lon_max = -180, 180\n",
    "lat_min, lat_max = -90, 90\n",
    "    \n",
    "SAA_map_bins_lon = 3\n",
    "SAA_map_bins_lat = 2\n",
    "x_bins_SAA = np.arange(lon_min + SAA_map_bins_lon, lon_max,SAA_map_bins_lon)\n",
    "y_bins_SAA = np.arange(lat_min + SAA_map_bins_lat, lat_max,SAA_map_bins_lat)\n",
    "\n",
    "SAA_masked_binned = binned_statistic_2d(x, y, c, statistic='median', bins=[x_bins_SAA, y_bins_SAA]).statistic.T\n",
    "lon, lat = np.meshgrid(x_bins_SAA, y_bins_SAA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAA_file_old = Path(\"ref_files\") / \"CH_TU2020-03-11T00-00-00_EXT_APP_SAAMap-700km_V0102.fits\" # pre-LTAN\n",
    "\n",
    "\n",
    "data_SAA_old = read_SAA_map(SAA_file_old)\n",
    "\n",
    "# Plot SAA mask\n",
    "x_old = data_SAA_old['longitude']\n",
    "y_old = data_SAA_old['latitude']\n",
    "c_old = data_SAA_old['SAA_FLAG']\n",
    "\n",
    "# Bin and maks SAA mask contour\n",
    "lon_min, lon_max = -180, 180\n",
    "lat_min, lat_max = -90, 90\n",
    "    \n",
    "SAA_map_bins_lon = 3\n",
    "SAA_map_bins_lat = 2\n",
    "x_bins_SAA_old = np.arange(lon_min + SAA_map_bins_lon, lon_max,SAA_map_bins_lon)\n",
    "y_bins_SAA_old = np.arange(lat_min + SAA_map_bins_lat, lat_max,SAA_map_bins_lat)\n",
    "\n",
    "SAA_masked_binned_old = binned_statistic_2d(x_old, y_old, c_old, statistic='median', bins=[x_bins_SAA_old, y_bins_SAA_old]).statistic.T\n",
    "lon_old, lat_old = np.meshgrid(x_bins_SAA_old, y_bins_SAA_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%matplotlib widget\n",
    "# plt.close('all')\n",
    "# fig = plt.figure(figsize=figsize)\n",
    "\n",
    "# ax = plt.axes(projection=projection)\n",
    "# ax.stock_img()\n",
    "# ax.gridlines()\n",
    "\n",
    "# plt.contour(lon[1:,1:], lat[1:,1:], SAA_masked_binned, colors = 'white', linewidths = 2, levels=[0], origin='lower', extent=(lon_min, lon_max, lat_min, lat_max),transform=ccrs.PlateCarree())\n",
    "\n",
    "# labels = ['< 3 (less than 5 hits/sec on the CCD) ','3-30 (5-50 hits/sec on the CCD) ','30-300 (50-500 hits/sec on the CCD) ', '> 300 (> 500 hits per sec on the CCD)']\n",
    "# colors = ['white','gold','C1','C3']\n",
    "# cm = ListedColormap(colors)\n",
    "# for i in range(4):\n",
    "#     if i == 0:\n",
    "#         continue\n",
    "#         x = data_plot.loc[data_plot['density_cosmics'] < 3]['LONGITUDE']\n",
    "#         y = data_plot.loc[data_plot['density_cosmics'] < 3]['LATITUDE']\n",
    "#         alpha = 0.5\n",
    "        \n",
    "#     if i == 1:\n",
    "#         x = data_plot.loc[(data_plot['density_cosmics'] > 3) & (data_plot['density_cosmics'] < 30)]['LONGITUDE']\n",
    "#         y = data_plot.loc[(data_plot['density_cosmics'] > 3) & (data_plot['density_cosmics'] < 30)]['LATITUDE']\n",
    "#         alpha = 0.7\n",
    "        \n",
    "#     if i == 2:\n",
    "#         x = data_plot.loc[(data_plot['density_cosmics'] >= 30) & (data_plot['density_cosmics'] < 300)]['LONGITUDE']\n",
    "#         y = data_plot.loc[(data_plot['density_cosmics'] >= 30) & (data_plot['density_cosmics'] < 300)]['LATITUDE']\n",
    "#         alpha = 0.7\n",
    "    \n",
    "        \n",
    "#     if i == 3:\n",
    "#         x = data_plot.loc[data_plot['density_cosmics'] >= 300]['LONGITUDE']\n",
    "#         y = data_plot.loc[data_plot['density_cosmics'] >= 300]['LATITUDE']\n",
    "#         alpha = 0.7\n",
    "    \n",
    "#     cr = plt.scatter(x,y,c = colors[i], s = 20, alpha = alpha, marker = 'o', transform=ccrs.Geodetic(), label = labels[i])\n",
    "\n",
    "# handles = [\n",
    "#     plt.scatter([], [], s=100, c=colors[0], alpha=0.6, label=labels[0]),\n",
    "#     plt.scatter([], [], s=100, c=colors[1], alpha=0.6, label=labels[1]),\n",
    "#     plt.scatter([], [], s=100, c=colors[2], alpha=0.6, label=labels[2]),\n",
    "#     plt.scatter([], [], s=100, c=colors[3], alpha=0.6, label=labels[3]),\n",
    "\n",
    "# ]\n",
    "\n",
    "# # Add legend to the plot with custom background color\n",
    "# legend = plt.legend(handles=handles, title=\"hits/cm2/s\")\n",
    "# legend.get_frame().set_facecolor('white')    \n",
    "\n",
    "# title = 'Cosmic Rays density ' + data_plot.time.min().strftime('%Y-%m-%d') + ' to ' + data_plot.time.max().strftime('%Y-%m-%d')\n",
    "# plt.title(title, weight = 'bold')\n",
    "# fileout_name = \"no_filters_CR_density_visits_discrete_\" + data_plot.time.min().strftime('%Y-%m-%d') + \"_to_\" + data_plot.time.max().strftime('%Y-%m-%d')+ \".png\"\n",
    "# plt.savefig(output_folder / fileout_name, transparent = False, dpi = 600,format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affected_visits = np.array(['10_12_39_1', '10_18_403_3', '10_18_437_2',\n",
    "       '10_18_442_3', '10_18_497_5', '10_18_498_4', '10_18_525_2',\n",
    "       '10_24_163_1', '10_25_81_1', '13_57_37_10', '13_57_37_9',\n",
    "       '14_61_5_3', '14_63_14_3', '14_63_14_4', '14_66_4_2', '14_66_4_3',\n",
    "       '14_71_8_3', '14_76_1_4', '14_76_1_5', '14_79_2_1', '14_80_10_2',\n",
    "       '14_80_12_1', '14_84_23_1', '14_84_23_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,visit_ID in enumerate(affected_visits):\n",
    "    data_visit = map_data[map_data['visit_ID'] == visit_ID].iloc[0]\n",
    "    v_id = 'PR' + data_visit['visit_ID'].split('_')[0] + data_visit['visit_ID'].split('_')[1].zfill(4) + \"_TG\" + data_visit['visit_ID'].split('_')[2].zfill(4) + data_visit['visit_ID'].split('_')[3].zfill(2)\n",
    "    print(f\"{v_id} | {data_visit['target_name']} | Gmag = {data_visit['mag_G']} | exp time = {np.round(data_visit['exp_time'],0)} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = plt.axes(projection=projection)\n",
    "\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "\n",
    "\n",
    "# Plot SAA contour\n",
    "SAA_current = plt.contour(lon[1:,1:], lat[1:,1:], SAA_masked_binned, colors = 'grey', linewidths = 2,  alpha = 1,levels=[0], origin='lower', extent=(lon_min, lon_max, lat_min, lat_max),transform=ccrs.PlateCarree())\n",
    "SAA_current = plt.contour(lon[1:,1:], lat[1:,1:], SAA_masked_binned, levels=[1], origin='lower', extent=(lon_min, lon_max, lat_min, lat_max),transform=ccrs.PlateCarree())\n",
    "h3,_ = SAA_current.legend_elements()\n",
    "plt.legend([h3[0]], ['Current mask'])\n",
    "\n",
    "x = data_plot[x_values]\n",
    "y = data_plot[y_values]\n",
    "c = data_plot[hue_values]\n",
    "\n",
    "binned_data, _, _, lon_data, lat_data  = bin_data(x,y,c, interpolation='base_grid', type = hue_values)\n",
    "   \n",
    "plt.contour(lon_data, lat_data, binned_data, levels=[1], origin='lower', extent=(lon_min, lon_max, lat_min, lat_max),transform=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "SAA_map_plot = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o', norm=LogNorm(), cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i])\n",
    "# SAA_map_plot = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o', cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i])\n",
    "\n",
    "# SAA_map_plot = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, transform=ccrs.PlateCarree()) \n",
    "#SAA_map_plot = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, norm = LogNorm(), transform=ccrs.PlateCarree()) \n",
    "\n",
    "# SAA_map_plot = plt.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o', norm = LogNorm(), cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i])\n",
    "# SAA_map_plot = plt.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o',cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i])\n",
    "\n",
    "if hue_values == 'percentage_cosmics':\n",
    "    cbar = plt.colorbar(SAA_map_plot, label = '% of affected pixels', shrink=0.6)\n",
    "    cbar.formatter = FormatStrFormatter(\"%.2f\")\n",
    "    cbar.update_ticks()\n",
    "else:\n",
    "    cbar = plt.colorbar(SAA_map_plot, label = 'hits/cm2/s', shrink=0.6)\n",
    "\n",
    "# #plt.title('June 28th, at 08:40:00, SAA_FLAG is False in MPS_PRE_VISIT')\n",
    "# #plt.legend(frameon=True,bbox_to_anchor=(0.7,0),markerscale=1)\n",
    "# #save_folder = '/Users/alexisheitzmann/Documents/CHEOPS/Code/SSA_mismapping/imagette_mapping/AU_Mic_5_sec_visits/'\n",
    "# name_addition = 'all'\n",
    "# save_name = 'map_CR_detections_'+ name_addition + '_' + np.min(full_orb_res_err.index).strftime(\"%Y-%m-%d\") + '_to_' + np.max(full_orb_res_err.index).strftime(\"%Y-%m-%d\") + '.png'\n",
    "#title = str(len(data_plot)) + ' detections from ' + np.min(full_orb_res_err.index).strftime(\"%Y-%m-%d\") + ' to ' + np.max(full_orb_res_err.index).strftime(\"%Y-%m-%d\")\n",
    "# title = 'Cosmic Rays density ' + data_plot.time.min().strftime('%Y-%m-%d') + ' to ' + data_plot.time.max().strftime('%Y-%m-%d')\n",
    "# title =  f\"{v_id} | {data_visit['target_name']}\"\n",
    "# plt.title(title, weight = 'bold')\n",
    "#fileout_name = \"CR_density_\" + data_plot.time.min().strftime('%Y-%m-%d') + \"_to_\" + data_plot.time.max().strftime('%Y-%m-%d')+ \".png\"\n",
    "# fileout_name = \"SAA_since_LTAN_all.png\"\n",
    "# plt.savefig(fileout_name, transparent = True, dpi = 600,format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation = 'None' \n",
    "# interpolation = 'base_grid' \n",
    "# interpolation = 'fine_grid' \n",
    "\n",
    "# Time between frames\n",
    "logscale = True\n",
    "time_resolution =  pd.Timedelta(weeks= 5)\n",
    "nb_maps = int(np.ceil((end_date - start_date)/time_resolution))\n",
    "\n",
    "\n",
    "def update_data(idx):\n",
    "    start = start_date + time_resolution*int(idx)\n",
    "    end  = start_date + time_resolution*(int(idx)+1)\n",
    "    data_between_dates = data_plot[(data_plot.time > start) & (data_plot.time < end)]\n",
    "    \n",
    "    x = data_between_dates[x_values]\n",
    "    y = data_between_dates[y_values]\n",
    "    c = data_between_dates[hue_values]\n",
    "    \n",
    "    plt.contour(lon[1:,1:], lat[1:,1:], SAA_masked_binned, colors = 'white', linewidths = 2, levels=[0], origin='lower', extent=(lon_min, lon_max, lat_min, lat_max),transform=ccrs.PlateCarree())\n",
    "    plt.scatter(south_mag_pole_coord[0], south_mag_pole_coord[1], s = 100, marker = 'X', transform=ccrs.PlateCarree(), label = \"South magnetic pole\")\n",
    "    circle_lat, circle_lon = circle_points(south_mag_pole_coord[1], south_mag_pole_coord[0], 23.44, num_points=120)\n",
    "    plt.plot(circle_lon, circle_lat, transform=ccrs.PlateCarree())\n",
    "\n",
    "    binned_data, _, _, _, _  = bin_data(x,y,c, interpolation=interpolation, type = hue_values)\n",
    "\n",
    "    return start,end,binned_data    \n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = plt.axes(projection=projection)\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "\n",
    "# Plot SAA contour\n",
    "plt.contour(lon[1:,1:], lat[1:,1:], SAA_masked_binned, colors = 'white', linewidths = 2, levels=[0], origin='lower', extent=(lon_min, lon_max, lat_min, lat_max),transform=ccrs.PlateCarree())\n",
    "plt.scatter(south_mag_pole_coord[0], south_mag_pole_coord[1], s = 100, marker = 'X', transform=ccrs.PlateCarree(), label = \"South magnetic pole\")\n",
    "circle_lat, circle_lon = circle_points(south_mag_pole_coord[1], south_mag_pole_coord[0], 23.44, num_points=120)\n",
    "plt.plot(circle_lon, circle_lat, transform=ccrs.PlateCarree())\n",
    "# Plot initial data\n",
    "x = data_plot[x_values]\n",
    "y = data_plot[y_values]\n",
    "c = data_plot[hue_values]\n",
    "\n",
    "binned_data, _, _, _, _  = bin_data(x,y,c, interpolation=interpolation, type = hue_values)\n",
    "   \n",
    "\n",
    "if logscale: \n",
    "    # cr = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o', norm=LogNorm(), cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i])\n",
    "    cr = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, extent=(lon_min, lon_max, lat_min, lat_max), norm = LogNorm(), transform=ccrs.PlateCarree()) \n",
    "    # Calculate the log range for the colorbar\n",
    "    # log_min = np.floor(np.log10(np.nanmin(data_plot[hue_values])+1))\n",
    "    # log_max = np.round(np.log10(np.nanmax(data_plot[hue_values])),1)\n",
    "    # #log_range = np.logspace(log_min, log_max, num=10)\n",
    "    # log_range = np.arange(log_min, log_max, 0.5)\n",
    "    # # Convert back from log scale to the original scale\n",
    "    # cbar_range = 10**log_range\n",
    "    # # Create a logarithmic norm for the color mapping\n",
    "    # log_norm = matplotlib.colors.LogNorm(vmin=10**log_min, vmax=10**log_max)\n",
    "    # # Create the colorbar with logarithmic ticks\n",
    "    # colorbar = fig.colorbar(cr, ax=ax, label='hits/cm2/s', ticks=cbar_range, norm=log_norm)\n",
    "    # colorbar.set_ticks(cbar_range)\n",
    "    # colorbar.set_ticklabels([f'{int(tick)}' for tick in cbar_range])\n",
    "\n",
    "else: \n",
    "    cr = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, extent=(lon_min, lon_max, lat_min, lat_max), transform=ccrs.PlateCarree()) \n",
    "    # cr = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o', cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i])\n",
    "    # colorbar = fig.colorbar(cr, ax=ax, label = 'hits/cm2/s')#, ticks=cbar_range)\n",
    "\n",
    "if hue_values == 'percentage_cosmics':\n",
    "    cbar = plt.colorbar(cr, label = '% of affected pixels', shrink=0.6)\n",
    "    cbar.formatter = FormatStrFormatter(\"%.2f\")\n",
    "    cbar.update_ticks()\n",
    "else:\n",
    "    cbar = plt.colorbar(cr, label = 'hits/cm2/s', shrink=0.6)\n",
    "\n",
    "def plotimg(idx):\n",
    "    \n",
    "    ax.clear()\n",
    "    ax.stock_img()\n",
    "    ax.gridlines()\n",
    "    # start = start_date + time_resolution*int(idx)\n",
    "    # end  = start_date + time_resolution*(int(idx)+1)\n",
    "    # data_between_dates = data_plot[(data_plot.time > start) & (data_plot.time < end)]\n",
    "    \n",
    "    # x = data_between_dates['LONGITUDE']\n",
    "    # y = data_between_dates['LATITUDE']\n",
    "    # c = data_between_dates['density_cosmics']\n",
    "    start,end, binned_data = update_data(idx)\n",
    "    if logscale:\n",
    "        cr = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, extent=(lon_min, lon_max, lat_min, lat_max), norm = LogNorm(), transform=ccrs.PlateCarree()) \n",
    "        #cr = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, norm=LogNorm(), marker = 'o', cmap='hot_r', transform=ccrs.Geodetic())#, label = labels[i])\n",
    "    else:\n",
    "        cr = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, extent=(lon_min, lon_max, lat_min, lat_max), transform=ccrs.PlateCarree()) \n",
    "        # cr = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o', cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i]\n",
    "    ax.set_title('Cosmic Rays density from ' + start.strftime('%d-%b-%Y') + ' to ' + end.strftime('%d-%b-%Y'), weight = 'bold')\n",
    "\n",
    "ipywidgets.interact(plotimg, idx = ipywidgets.FloatSlider(value=0,min=0,max=nb_maps-1,step=1))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def update_data(idx):\n",
    "    start = start_date + time_resolution*int(idx)\n",
    "    end  = start_date + time_resolution*(int(idx)+1)\n",
    "    data_between_dates = data_plot[(data_plot.time > start) & (data_plot.time < end)]\n",
    "    \n",
    "    x = data_between_dates[x_values]\n",
    "    y = data_between_dates[y_values]\n",
    "    c = data_between_dates[hue_values]\n",
    "    \n",
    "    plt.contour(lon[1:,1:], lat[1:,1:], SAA_masked_binned, colors = 'white', linewidths = 2, levels=[0], origin='lower', extent=(lon_min, lon_max, lat_min, lat_max),transform=ccrs.PlateCarree())\n",
    "    # plt.scatter(south_mag_pole_coord[0], south_mag_pole_coord[1], s = 100, marker = 'X', transform=ccrs.PlateCarree(), label = \"South magnetic pole\")\n",
    "    # circle_lat, circle_lon = circle_points(south_mag_pole_coord[1], south_mag_pole_coord[0], 23.44, num_points=120)\n",
    "    # plt.plot(circle_lon, circle_lat, transform=ccrs.PlateCarree())\n",
    "\n",
    "    binned_data, _, _, _, _  = bin_data(x,y,c, interpolation=interpolation, type = hue_values)\n",
    "    print(f\"Creating image {int(idx)}/{nb_maps}\")\n",
    "\n",
    "    return start,end,binned_data   \n",
    "\n",
    "# Assuming plotimg is your function that plots the image based on the idx\n",
    "# We'll rewrite plotimg slightly to work with FuncAnimation\n",
    "def plotimg(idx):\n",
    "    \n",
    "    ax.clear()\n",
    "    ax.stock_img()\n",
    "    ax.gridlines()\n",
    "    # start = start_date + time_resolution*int(idx)\n",
    "    # end  = start_date + time_resolution*(int(idx)+1)\n",
    "    # data_between_dates = data_plot[(data_plot.time > start) & (data_plot.time < end)]\n",
    "    \n",
    "    # x = data_between_dates['LONGITUDE']\n",
    "    # y = data_between_dates['LATITUDE']\n",
    "    # c = data_between_dates['density_cosmics']\n",
    "    start,end, binned_data = update_data(idx)\n",
    "    if logscale:\n",
    "        cr = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, extent=(lon_min, lon_max, lat_min, lat_max), norm = LogNorm(), transform=ccrs.PlateCarree()) \n",
    "        #cr = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, norm=LogNorm(), marker = 'o', cmap='hot_r', transform=ccrs.Geodetic())#, label = labels[i])\n",
    "    else:\n",
    "        cr = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, extent=(lon_min, lon_max, lat_min, lat_max), transform=ccrs.PlateCarree()) \n",
    "        # cr = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o', cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i]\n",
    "    mid_time = start + time_resolution/2\n",
    "    mid_label = mid_time.strftime('%B %Y')\n",
    "    ax.set_title(f\"{mid_label} \", fontsize = 18, weight = 'bold')\n",
    "    \n",
    "    SAA_current = plt.contour(lon[1:,1:], lat[1:,1:], SAA_masked_binned, colors = 'k', linewidths = 3,  alpha = 1,levels=[0], origin='lower', extent=(lon_min, lon_max, lat_min, lat_max),transform=ccrs.PlateCarree())\n",
    "    # h3,_ = SAA_current.legend_elements()\n",
    "    # if hue_values == 'percentage_cosmics':\n",
    "    #     cbar = plt.colorbar(SAA_map_plot, label = '% of affected pixels', shrink=0.6)\n",
    "    #     cbar.formatter = FormatStrFormatter(\"%.2f\")\n",
    "    #     cbar.update_ticks()\n",
    "    # else:\n",
    "    #     cbar = plt.colorbar(SAA_map_plot, label = 'hits/cm2/s', shrink=0.6)\n",
    "    # plt.legend([h3[0]], ['Current mask'])\n",
    "\n",
    "# Animation function to update the plot\n",
    "def update(frame):\n",
    "    plotimg(frame)\n",
    "\n",
    "# Create a figure for the animation\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = plt.axes(projection=projection)\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "\n",
    "interpolation = 'None' \n",
    "# interpolation = 'base_grid' \n",
    "# interpolation = 'fine_grid' \n",
    "\n",
    "# Time between frames\n",
    "logscale = True\n",
    "time_resolution =  pd.Timedelta(weeks= 2)\n",
    "nb_maps = int(np.ceil((end_date - start_date)/time_resolution))\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, update, frames=nb_maps, repeat=True)\n",
    "\n",
    "# Save the animation as an mp4 file without displaying\n",
    "ani.save('animation.gif', writer='ffmpeg', fps=10)  # Adjust fps as needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum CR hits under SAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data in the rectangle\n",
    "lat_n = -48\n",
    "lat_s = -71\n",
    "lon_w = -60\n",
    "lon_e = 35\n",
    "\n",
    "filter_rect = (data_plot[y_values] < lat_n) & (data_plot[y_values] > lat_s) & (data_plot[x_values] < lon_e) & (data_plot[x_values] > lon_w)\n",
    "data_area_under_SAA = data_plot[filter_rect]\n",
    "\n",
    "time_resolution =  pd.Timedelta(weeks=2)\n",
    "nb_maps = int(np.ceil((end_date - start_date)/time_resolution))\n",
    "\n",
    "time = np.array([])\n",
    "mean_density_cosmics = np.array([])\n",
    "mean_percentage = np.array([])\n",
    "max_percentage = np.array([])\n",
    "\n",
    "for i in range(nb_maps-1):\n",
    "    start = start_date + time_resolution*i\n",
    "    end  = start_date + time_resolution*(i+1)\n",
    "    mid_time = start + time_resolution/2\n",
    "    # mid_label = start.strftime('%B %Y')\n",
    "    \n",
    "    data_between_dates = data_area_under_SAA[(data_area_under_SAA.time > start) & (data_area_under_SAA.time < end)]\n",
    "\n",
    "    if len(data_between_dates) == 0:\n",
    "        time = np.append(time,mid_time)\n",
    "        mean_density_cosmics = np.append(mean_density_cosmics,np.nan)\n",
    "    else:\n",
    "        # Data binned at 5*5\n",
    "        x = data_between_dates[x_values]\n",
    "        y = data_between_dates[y_values]\n",
    "        binned_density, _, _, _, _ = bin_data(x,y,data_between_dates['density_cosmics'], interpolation='None', type = 'density_cosmics')\n",
    "        binned_percentage, _, _, _, _ = bin_data(x,y,data_between_dates['percentage_cosmics'], interpolation='None', type = 'percentage_cosmics')\n",
    "        time = np.append(time,mid_time)\n",
    "        mean_density_cosmics = np.append(mean_density_cosmics,np.nanmean(binned_density))\n",
    "        max_percentage = np.append(max_percentage,np.nanmax(binned_percentage))\n",
    "        mean_percentage = np.append(mean_percentage,np.nanmean(binned_percentage))\n",
    "        \n",
    "# # Save array\n",
    "# timestamps_str = np.array([ts.isoformat() for ts in time])\n",
    "# combined_array = np.column_stack((timestamps_str, mean_density_cosmics))\n",
    "# np.savetxt('1month.csv', combined_array, delimiter=',', header='Timestamp,Data', comments='', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "# Assuming plotimg is your function that plots the image based on the idx\n",
    "# We'll rewrite plotimg slightly to work with FuncAnimation\n",
    "def plotimg(idx):\n",
    "    \n",
    "    ax.clear()\n",
    "    ax.plot(time,mean_density_cosmics)\n",
    "    ax.set_ylabel(f'Mean CR hits in region (hits/cm2/s)', weight = 'bold')\n",
    "    # ax.axvline(start_AO1, c='C5', label = 'AO-1')\n",
    "    # ax.axvline(start_AO2, c='C1', label = 'AO-2')\n",
    "    # ax.axvline(start_AO3, c='C2',label = 'AO-3')\n",
    "    # ax.axvline(start_AO4, c='C3', label = 'AO-4')\n",
    "    # ax.axvline(start_AO5, c='C4',label = 'AO-5')\n",
    "    ax.axvline(pd.Timestamp(\"2021-01-01 12:00:00\", tz = 'UTC'), c='C5', label = '2021')\n",
    "    ax.axvline(pd.Timestamp(\"2022-01-01 12:00:00\", tz = 'UTC'), c='C1', label = '2022')\n",
    "    ax.axvline(pd.Timestamp(\"2023-01-01 12:00:00\", tz = 'UTC'), c='C2',label = '2023')\n",
    "    ax.axvline(pd.Timestamp(\"2024-01-01 12:00:00\", tz = 'UTC'), c='C3', label = '2024')\n",
    "    ax.axvline(time[idx], linewidth = 1, color = 'k')\n",
    "    ax.legend()\n",
    "    # ax.tight_layout()\n",
    "\n",
    "# Animation function to update the plot\n",
    "def update(frame):\n",
    "    plotimg(frame)\n",
    "\n",
    "# Create a figure for the animation\n",
    "fig,ax = plt.subplots(figsize = (8,4))\n",
    "\n",
    "time_resolution =  pd.Timedelta(weeks= 2)\n",
    "nb_maps = int(np.ceil((end_date - start_date)/time_resolution))\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, update, frames=nb_maps-1, repeat=True)\n",
    "\n",
    "# Save the animation as an mp4 file without displaying\n",
    "ani.save('animated_plot_mean_cr_hits.gif', writer='ffmpeg', fps=10)  # Adjust fps as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_AO1 = pd.Timestamp(\"2020-02-01 12:00:00\", tz = 'UTC')\n",
    "start_AO2 = pd.Timestamp(\"2021-03-26 12:00:00\", tz = 'UTC')\n",
    "start_AO3 = pd.Timestamp(\"2022-07-01 12:00:00\", tz = 'UTC')\n",
    "start_AO4 = pd.Timestamp(\"2023-09-25 12:00:00\", tz = 'UTC')\n",
    "start_AO5 = pd.Timestamp(\"2024-10-01 12:00:00\", tz = 'UTC')\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv('1month.csv', delimiter=',')\n",
    "# time = pd.to_datetime(df['Timestamp'])\n",
    "# mean_density_cosmics = pd.to_numeric(df['Data'])\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (8,4))\n",
    "ax.plot(time,mean_density_cosmics)\n",
    "ax.tick_params(axis='x', rotation=0) \n",
    "ax.set_ylabel(f'Mean CR hits in region (hits/cm2/s)')\n",
    "ax.axvline(start_AO1, c='C0', label = 'AO-1')\n",
    "ax.axvline(start_AO2, c='C1', label = 'AO-2')\n",
    "ax.axvline(start_AO3, c='C2',label = 'AO-3')\n",
    "ax.axvline(start_AO4, c='C5', label = 'AO-4')\n",
    "ax.axvline(start_AO5, c='C4',label = 'AO-5')\n",
    "\n",
    "ax.legend(loc = 'upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_AO1 = pd.Timestamp(\"2020-02-01 12:00:00\", tz = 'UTC')\n",
    "start_AO2 = pd.Timestamp(\"2021-03-26 12:00:00\", tz = 'UTC')\n",
    "start_AO3 = pd.Timestamp(\"2022-07-01 12:00:00\", tz = 'UTC')\n",
    "start_AO4 = pd.Timestamp(\"2023-09-25 12:00:00\", tz = 'UTC')\n",
    "start_AO5 = pd.Timestamp(\"2024-10-01 12:00:00\", tz = 'UTC')\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv('1month.csv', delimiter=',')\n",
    "# time = pd.to_datetime(df['Timestamp'])\n",
    "# mean_density_cosmics = pd.to_numeric(df['Data'])\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (8,4))\n",
    "ax.plot(time,mean_percentage)\n",
    "ax.tick_params(axis='x', rotation=0) \n",
    "ax.set_ylabel(f'Mean percentage of affected pixels')\n",
    "ax.axvline(start_AO1, c='C0', label = 'AO-1')\n",
    "ax.axvline(start_AO2, c='C1', label = 'AO-2')\n",
    "ax.axvline(start_AO3, c='C2',label = 'AO-3')\n",
    "ax.axvline(start_AO4, c='C5', label = 'AO-4')\n",
    "ax.axvline(start_AO5, c='C4',label = 'AO-5')\n",
    "\n",
    "ax.legend(loc = 'upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(binned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(binned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation = 'None' \n",
    "# interpolation = 'base_grid' \n",
    "# interpolation = 'fine_grid' \n",
    "\n",
    "# Time between frames\n",
    "logscale = True\n",
    "time_resolution =  pd.Timedelta(days= 1)\n",
    "nb_maps = int(np.ceil((end_date - start_date)/time_resolution))\n",
    "\n",
    "# Get data in the rectangle\n",
    "lat_n = -48\n",
    "lat_s = -71\n",
    "lon_w = -60\n",
    "lon_e = 35\n",
    "\n",
    "filter_rect = (data_plot[y_values] < lat_n) & (data_plot[y_values] > lat_s) & (data_plot[x_values] < lon_e) & (data_plot[x_values] > lon_w)\n",
    "data_filtered = data_plot[filter_rect]\n",
    "    \n",
    "def update_data(idx):\n",
    "    start = start_date + time_resolution*int(idx)\n",
    "    end  = start_date + time_resolution*(int(idx)+1)\n",
    "    data_between_dates = data_filtered[(data_plot.time > start) & (data_plot.time < end)]\n",
    "    \n",
    "    # Data binned at 5*5\n",
    "    x = data_between_dates[x_values]\n",
    "    y = data_between_dates[y_values]\n",
    "    c = data_between_dates[hue_values]\n",
    "    binned_data, _, _, _, _ = bin_data(x,y,c, interpolation='base_grid', type = hue_values)\n",
    "    \n",
    "    plt.contour(lon[1:,1:], lat[1:,1:], SAA_masked_binned, colors = 'white', linewidths = 2, levels=[0], origin='lower', extent=(lon_min, lon_max, lat_min, lat_max),transform=ccrs.PlateCarree())\n",
    "    plt.scatter(south_mag_pole_coord[0], south_mag_pole_coord[1], s = 100, marker = 'X', transform=ccrs.PlateCarree(), label = \"South magnetic pole\")\n",
    "    circle_lat, circle_lon = circle_points(south_mag_pole_coord[1], south_mag_pole_coord[0], 23.44, num_points=120)\n",
    "    plt.plot(circle_lon, circle_lat, transform=ccrs.PlateCarree())\n",
    "\n",
    "    binned_data, _, _, _, _  = bin_data(x,y,c, interpolation=interpolation, type = hue_values)\n",
    "\n",
    "    return start,end,binned_data    \n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = plt.axes(projection=projection)\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "\n",
    "# Plot SAA contour\n",
    "plt.contour(lon[1:,1:], lat[1:,1:], SAA_masked_binned, colors = 'white', linewidths = 2, levels=[0], origin='lower', extent=(lon_min, lon_max, lat_min, lat_max),transform=ccrs.PlateCarree())\n",
    "plt.scatter(south_mag_pole_coord[0], south_mag_pole_coord[1], s = 100, marker = 'X', transform=ccrs.PlateCarree(), label = \"South magnetic pole\")\n",
    "circle_lat, circle_lon = circle_points(south_mag_pole_coord[1], south_mag_pole_coord[0], 23.44, num_points=120)\n",
    "plt.plot(circle_lon, circle_lat, transform=ccrs.PlateCarree())\n",
    "\n",
    "# Data binned at 5*5\n",
    "x = data_filtered[x_values]\n",
    "y = data_filtered[y_values]\n",
    "c = data_filtered[hue_values]\n",
    "binned_filtered_data, _, _, _, _ = bin_data(x,y,c, interpolation='base_grid', type = hue_values)\n",
    "   \n",
    "\n",
    "if logscale: \n",
    "    # cr = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o', norm=LogNorm(), cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i])\n",
    "    cr = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, extent=(lon_min, lon_max, lat_min, lat_max), norm = LogNorm(), transform=ccrs.PlateCarree()) \n",
    "    # Calculate the log range for the colorbar\n",
    "    # log_min = np.floor(np.log10(np.nanmin(data_plot[hue_values])+1))\n",
    "    # log_max = np.round(np.log10(np.nanmax(data_plot[hue_values])),1)\n",
    "    # #log_range = np.logspace(log_min, log_max, num=10)\n",
    "    # log_range = np.arange(log_min, log_max, 0.5)\n",
    "    # # Convert back from log scale to the original scale\n",
    "    # cbar_range = 10**log_range\n",
    "    # # Create a logarithmic norm for the color mapping\n",
    "    # log_norm = matplotlib.colors.LogNorm(vmin=10**log_min, vmax=10**log_max)\n",
    "    # # Create the colorbar with logarithmic ticks\n",
    "    # colorbar = fig.colorbar(cr, ax=ax, label='hits/cm2/s', ticks=cbar_range, norm=log_norm)\n",
    "    # colorbar.set_ticks(cbar_range)\n",
    "    # colorbar.set_ticklabels([f'{int(tick)}' for tick in cbar_range])\n",
    "\n",
    "else: \n",
    "    cr = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, extent=(lon_min, lon_max, lat_min, lat_max), transform=ccrs.PlateCarree()) \n",
    "    # cr = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o', cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i])\n",
    "    # colorbar = fig.colorbar(cr, ax=ax, label = 'hits/cm2/s')#, ticks=cbar_range)\n",
    "\n",
    "if hue_values == 'percentage_cosmics':\n",
    "    cbar = plt.colorbar(cr, label = '% of affected pixels', shrink=0.6)\n",
    "    cbar.formatter = FormatStrFormatter(\"%.2f\")\n",
    "    cbar.update_ticks()\n",
    "else:\n",
    "    cbar = plt.colorbar(cr, label = 'hits/cm2/s', shrink=0.6)\n",
    "\n",
    "def plotimg(idx):\n",
    "    \n",
    "    ax.clear()\n",
    "    ax.stock_img()\n",
    "    ax.gridlines()\n",
    "    # start = start_date + time_resolution*int(idx)\n",
    "    # end  = start_date + time_resolution*(int(idx)+1)\n",
    "    # data_between_dates = data_plot[(data_plot.time > start) & (data_plot.time < end)]\n",
    "    \n",
    "    # x = data_between_dates['LONGITUDE']\n",
    "    # y = data_between_dates['LATITUDE']\n",
    "    # c = data_between_dates['density_cosmics']\n",
    "    start,end, binned_data = update_data(idx)\n",
    "    if logscale:\n",
    "        cr = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, extent=(lon_min, lon_max, lat_min, lat_max), norm = LogNorm(), transform=ccrs.PlateCarree()) \n",
    "        #cr = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, norm=LogNorm(), marker = 'o', cmap='hot_r', transform=ccrs.Geodetic())#, label = labels[i])\n",
    "    else:\n",
    "        cr = ax.imshow(binned_data, origin='lower', alpha = 0.7, cmap = color_map, extent=(lon_min, lon_max, lat_min, lat_max), transform=ccrs.PlateCarree()) \n",
    "        # cr = ax.scatter(x,y,c = c, s = 5, alpha = 0.7, marker = 'o', cmap=color_map, transform=ccrs.Geodetic())#, label = labels[i]\n",
    "    ax.set_title('Cosmic Rays density from ' + start.strftime('%d-%b-%Y') + ' to ' + end.strftime('%d-%b-%Y'), weight = 'bold')\n",
    "\n",
    "ipywidgets.interact(plotimg, idx = ipywidgets.FloatSlider(value=0,min=0,max=nb_maps-1,step=1))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data binned at 5*5\n",
    "x = data_plot[x_values]\n",
    "y = data_plot[y_values]\n",
    "c = data_plot[hue_values]\n",
    "statistic, longitudes, latitudes = bin_data(x,y,c, interpolation='base_grid', type = hue_values)\n",
    "\n",
    "# SAA data binned at 5*5\n",
    "x = data_SAA['longitude']\n",
    "y = data_SAA['latitude']\n",
    "c = data_SAA['SAA_FLAG']\n",
    "\n",
    "# Bin and maks SAA mask contour\n",
    "lon_min, lon_max = -180, 180\n",
    "lat_min, lat_max = -90, 90\n",
    "\n",
    "SAA_map_bins_lon = 5\n",
    "SAA_map_bins_lat = 5\n",
    "x_bins_SAA = np.arange(lon_min + SAA_map_bins_lon, lon_max,SAA_map_bins_lon)\n",
    "y_bins_SAA = np.arange(lat_min + SAA_map_bins_lat, lat_max,SAA_map_bins_lat)\n",
    "\n",
    "SAA_masked_binned = binned_statistic_2d(x, y, c, statistic='median', bins=[x_bins_SAA, y_bins_SAA]).statistic.T\n",
    "\n",
    "in_SAA_lon = x_bins_SAA[np.unique(np.where(SAA_masked_binned > 0)[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "# Create a colormap\n",
    "cmap = plt.get_cmap('viridis')\n",
    "norm = mcolors.Normalize(vmin=np.min(in_SAA_lon), vmax=np.max(in_SAA_lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_plotted_lon = []\n",
    "min_hits = 200\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for i in range(len(longitudes)):\n",
    "    in_SAA = np.where(SAA_masked_binned[:,i] > 0)[0]\n",
    "    if len(in_SAA) == 0:\n",
    "        non_plotted_lon.append(longitudes[i])\n",
    "        continue\n",
    "    else:\n",
    "        ax.plot(latitudes, statistic[:,i], color = cmap(norm(longitudes[i])), label = longitudes[i])\n",
    "    # plt.yscale('log')\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Only needed for the colorbar\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label('Longitude')\n",
    "ax.set_xlabel(\"Latitude\")\n",
    "ax.set_ylabel(\"Hits/cm2/sec\")\n",
    "print(f\"The following Longitudes were not plotted as the max hits/cm2/sec < {min_hits}:\")\n",
    "print(non_plotted_lon)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shift_factor_y = 20\n",
    "shift_factor_x = 5\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for i in range(len(longitudes)-1):\n",
    "    in_SAA = np.where(SAA_masked_binned[:,i] > 0)[0]\n",
    "    if len(in_SAA) == 0:\n",
    "        non_plotted_lon.append(longitudes[i])\n",
    "        continue\n",
    "    else:\n",
    "        #plt.plot(latitudes[:-1], statistic[i,:]- i*shift_factor, color = colors[c_i], label = longitudes[i])\n",
    "        y1 = np.zeros(shape= np.shape(statistic[:,i]))- i*shift_factor_y\n",
    "        y2 = statistic[:,i]- i*shift_factor_y\n",
    "        plt.fill_between(latitudes[:]+shift_factor_x*i, y1, y2, where=(y2>=y1), color = cmap(norm(longitudes[i])), label = longitudes[i], alpha = 0.3)\n",
    "        ind_lat_min_SAA = in_SAA[0]\n",
    "        ind_lat_max_SAA = in_SAA[-1]\n",
    "        #plt.plot(latitudes[ind_lat_min_SAA], statistic[i,ind_lat_min_SAA]-i*shift_factor, 'o', color = colors[c_i])\n",
    "        #plt.plot(latitudes[ind_lat_max_SAA],statistic[i,ind_lat_max_SAA]-i*shift_factor, 'o', color = colors[c_i])\n",
    "        plt.plot(latitudes[ind_lat_min_SAA]+shift_factor_x*i, -i*shift_factor_y, '.', color = cmap(norm(longitudes[i])), zorder = 0)\n",
    "        plt.plot(latitudes[ind_lat_max_SAA]+shift_factor_x*i,-i*shift_factor_y, '.', color = cmap(norm(longitudes[i])), zorder = 0)\n",
    "\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Only needed for the colorbar\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label('Longitude')\n",
    "ax.set_xlabel(f\"Latitude (shifted by i*{shift_factor_y})\")\n",
    "ax.set_ylabel(f\"Hits/cm2/sec - (i*{shift_factor_y})\")\n",
    "print(f\"The following Longitudes were not plotted as the max hits/cm2/sec < {min_hits}:\")\n",
    "print(non_plotted_lon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_density = np.nanmax(statistic[:,:])\n",
    "\n",
    "plt.close('all')\n",
    "c_i = 0\n",
    "for i in range(len(longitudes)-1):\n",
    "    in_SAA = np.where(SAA_masked_binned.T[i,:] > 0)[0]\n",
    "    if len(in_SAA) == 0:\n",
    "        non_plotted_lon.append(longitudes[i])\n",
    "        continue\n",
    "    plt.figure()\n",
    "    plt.plot(latitudes[:], statistic[:,i], color = cmap(norm(longitudes[i])))\n",
    "    plt.axvline(latitudes[in_SAA[0]],0,statistic[:,i].max(), color = 'indianred',alpha = 0.6, label = 'SAA bounds')\n",
    "    plt.axvline(latitudes[in_SAA[-1]],0,statistic[:,i].max(), color = 'indianred',alpha = 0.6)\n",
    "    plt.axhline(max_density,latitudes[0],latitudes[-1], color = 'grey', alpha = 0.6, label = 'Max cosmic density value in map')\n",
    "    plt.title(f\"Longitude = {longitudes[i]}\")\n",
    "    c_i += 1\n",
    "    plt.xlabel(\"Latitude\") \n",
    "    plt.ylabel(f\"Hits/cm2/sec\")\n",
    "    plt.legend()\n",
    "\n",
    "print(f\"The following Longitudes were not plotted as the max hits/cm2/sec < {min_hits}:\")\n",
    "print(non_plotted_lon)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit gaussian to lon -57.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_plotted_lon = []\n",
    "min_hits = 200\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for i in range(len(longitudes)):\n",
    "    in_SAA = np.where(SAA_masked_binned[:,i] > 0)[0]\n",
    "    if len(in_SAA) == 0:\n",
    "        non_plotted_lon.append(longitudes[i])\n",
    "        continue\n",
    "    else:\n",
    "        ax.plot(latitudes, statistic[:,i], color = cmap(norm(longitudes[i])), label = longitudes[i])\n",
    "    # plt.yscale('log')\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Only needed for the colorbar\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label('Longitude')\n",
    "ax.set_xlabel(\"Latitude\")\n",
    "ax.set_ylabel(\"Hits/cm2/sec\")\n",
    "print(f\"The following Longitudes were not plotted as the max hits/cm2/sec < {min_hits}:\")\n",
    "print(non_plotted_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_density = np.nanmax(statistic[:,:])\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "\n",
    "plt.plot(latitudes[:], statistic[:,i], color = cmap(norm(longitudes[i])))\n",
    "plt.axvline(latitudes[in_SAA[0]],0,statistic[:,i].max(), color = 'indianred',alpha = 0.6, label = 'SAA bounds')\n",
    "plt.axvline(latitudes[in_SAA[-1]],0,statistic[:,i].max(), color = 'indianred',alpha = 0.6)\n",
    "plt.axhline(max_density,latitudes[0],latitudes[-1], color = 'grey', alpha = 0.6, label = 'Max cosmic density value in map')\n",
    "plt.title(f\"Longitude = {longitudes[i]}\")\n",
    "c_i += 1\n",
    "plt.xlabel(\"Latitude\") \n",
    "plt.ylabel(f\"Hits/cm2/sec\")\n",
    "plt.legend()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3109",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
